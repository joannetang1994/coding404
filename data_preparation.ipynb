{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "data-preparation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joannetang1994/coding404/blob/main/data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2zixjQ60SoE"
      },
      "source": [
        "<img src=\"https://static.wincacademy.nl/logos/main-logo.png\" height=200px style=\"height: 200px\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43QBq79D0SoT"
      },
      "source": [
        "!pip install matplotlib --user > /dev/null 2>&1\n",
        "!pip install numpy --user > /dev/null 2>&1\n",
        "!pip install pandas --user > /dev/null 2>&1\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izLCI2980SoV"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "## CSV\n",
        "\n",
        "Let's talk about the messy part of data analytics: preparing data. Before doing the interesting work of data analytics, we need to:\n",
        "\n",
        "1. Gather the data.\n",
        "2. Structure the data in such a way that we can work with it in our programs.\n",
        "3. Clean the data, which may include dealing with missing or unreasonable values.\n",
        "\n",
        "Here we'll assume gathering the data has been done for us. We'll use a dataset provided by the Dutch *Rijksinstituut voor Volksgezondheid en Milieu* (RIVM, translation: National Institute for Health and Environment). It contains COVID-19 numbers per municipality per day. You should place a copy of the data in a file called `covid-data.csv` located in the same folder as this notebook (be it in Google Colab or locally). You can use the URL below to retrieve it.\n",
        "\n",
        "- Source: Rijksinstituut voor Volksgezondheid en Milieu\n",
        "- Data URL: https://data.rivm.nl/covid-19/COVID-19_aantallen_gemeente_per_dag.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjd7LGDG0SoW"
      },
      "source": [
        "data_loc = 'covid-data.csv'\n",
        "covid_data = open(data_loc).read()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQsR9y9F0SoX"
      },
      "source": [
        "Let's take a look at what it looks like by printing the first 1000 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOejl7Zv0SoY",
        "outputId": "9fe520d5-dede-4e62-e0ad-acc2e876342b"
      },
      "source": [
        "print(covid_data[:1000])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date_of_report;Date_of_publication;Municipality_code;Municipality_name;Province;Security_region_code;Security_region_name;Municipal_health_service;ROAZ_region;Total_reported;Hospital_admission;Deceased\n",
            "24-3-2021 10:00;27-2-2020;GM0014;Groningen;Groningen;VR01;Groningen;GGD Groningen;Acute Zorgnetwerk Noord Nederland;0;0;0\n",
            "24-3-2021 10:00;27-2-2020;GM0034;Almere;Flevoland;VR25;Flevoland;GGD Flevoland;SpoedZorgNet;0;0;0\n",
            "24-3-2021 10:00;27-2-2020;GM0037;Stadskanaal;Groningen;VR01;Groningen;GGD Groningen;Acute Zorgnetwerk Noord Nederland;0;0;0\n",
            "24-3-2021 10:00;27-2-2020;GM0047;Veendam;Groningen;VR01;Groningen;GGD Groningen;Acute Zorgnetwerk Noord Nederland;0;0;0\n",
            "24-3-2021 10:00;27-2-2020;GM0050;Zeewolde;Flevoland;VR25;Flevoland;GGD Flevoland;SpoedZorgNet;0;0;0\n",
            "24-3-2021 10:00;27-2-2020;GM0059;Achtkarspelen;Fryslân;VR02;Fryslân;GGD Fryslân;Acute Zorgnetwerk Noord Nederland;0;0;0\n",
            "24-3-2021 10:00;27-2-2020;GM0060;Ameland;Fryslân;VR02;Fryslân;GGD Fryslân;Acute Zorgnetwerk Noord Nederland;0;0;0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVhHceU_0SoY"
      },
      "source": [
        "That looks pretty chaotic. The data is in a format called `csv`, which is a commonly used format to store and share data.\n",
        "\n",
        "1. A `csv` file contains only text.\n",
        "2. The first line a `csv` file lists column names.\n",
        "3. Each line after that is a datapoint with values for those columns in the same order.\n",
        "\n",
        "Let's look at the first 3 lines instead of the first 1000 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0RgY3J10SoZ",
        "outputId": "1860c1ff-99eb-44b5-9eaa-645705cf1ddb"
      },
      "source": [
        "for line in covid_data.split('\\n')[:3]:\n",
        "    print(line)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date_of_report;Date_of_publication;Municipality_code;Municipality_name;Province;Security_region_code;Security_region_name;Municipal_health_service;ROAZ_region;Total_reported;Hospital_admission;Deceased\n",
            "24-3-2021 10:00;27-2-2020;GM0014;Groningen;Groningen;VR01;Groningen;GGD Groningen;Acute Zorgnetwerk Noord Nederland;0;0;0\n",
            "24-3-2021 10:00;27-2-2020;GM0034;Almere;Flevoland;VR25;Flevoland;GGD Flevoland;SpoedZorgNet;0;0;0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rJE3J2V0Soa"
      },
      "source": [
        "**1. What are the column names for this dataset? List them here.**\n",
        "\n",
        "*TODO: \n",
        "- Date_of_report\n",
        "- Date_of_publication\n",
        "- Municipality_code\n",
        "- Municipality_name\n",
        "- Province\n",
        "- Security_region_code\n",
        "- Security_region_name\n",
        "- Municipal_health_service\n",
        "- ROAZ_region\n",
        "- Total_reported\n",
        "- Hospital_admission\n",
        "- Deceased\n",
        "\n",
        "\n",
        "- First column\n",
        "- Second column\n",
        "- ...\n",
        "\n",
        "**2. Which character separates the datapoints from each other? Put an `x` in the right box.**\n",
        "\n",
        "- [ x] A linebreak\n",
        "- [ ] A tab\n",
        "- [ ] A comma\n",
        "\n",
        "**3. Which character separates the columns within a datapoint from each other?**\n",
        "\n",
        "*TODO: a semicolon\n",
        "\n",
        "\n",
        "### Parsing\n",
        "\n",
        "Let's use this information to read the data into our program in a better way. This is known as [*parsing*](https://en.wikipedia.org/wiki/Parsing). Our goal is to structure the data in such a way that we'll be able to write code like this to make it easier to work with the data:\n",
        "\n",
        "```python\n",
        "# For some datapoint, show me the municipality that it concerns.\n",
        "some_datapoint['Municipality_name']\n",
        "```\n",
        "\n",
        "By answering the questions above we have all the information we need to organize the internal *data structure* in this way.\n",
        "\n",
        "- We know what separates datapoints from each other.\n",
        "- We know how columns are separated within datapoints.\n",
        "- We have the column names for each datapoint.\n",
        "\n",
        "We can use this information to instruct Python -- the programming language we're using here -- to create a *data structure* that we can use like in the example above. Once completed, we'll have *parsed* the CSV file.\n",
        "\n",
        "**4. What is parsing in your own words?**\n",
        "\n",
        "*TODO: it is the process of analyzing symbols. For instance: a computerlanguage like python. But in python, we use the phrase syntax analysis often. \n",
        "It is to analyze or separate the components\n",
        "\n",
        "**5. Fill in the right column delimiter in the code cell below to complete the code.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHuNQ33t0Sob",
        "outputId": "4c8bd7d2-188d-43ab-933b-12921169e220"
      },
      "source": [
        "# TODO: Change 'PLACEHOLDER to the actual delimiter.\n",
        "delimiter = ';'\n",
        "# Make sure the delimiter is surrounded by quotes, for example: delimiter = '<' if the delimiter is <\n",
        "\n",
        "with open(data_loc) as f:\n",
        "    csv_reader = csv.DictReader(f, delimiter=delimiter)\n",
        "    print('Municipality name\\tTotal cases reported')\n",
        "    print('{:=>45}'.format(''))\n",
        "    data_dicts = list(csv_reader)\n",
        "\n",
        "for row in data_dicts[:15]:\n",
        "    print('{:<23} {:<5}'.format(row['Municipality_name'], row['Total_reported']))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Municipality name\tTotal cases reported\n",
            "=============================================\n",
            "Groningen               0    \n",
            "Almere                  0    \n",
            "Stadskanaal             0    \n",
            "Veendam                 0    \n",
            "Zeewolde                0    \n",
            "Achtkarspelen           0    \n",
            "Ameland                 0    \n",
            "Harlingen               0    \n",
            "Heerenveen              0    \n",
            "Leeuwarden              0    \n",
            "Ooststellingwerf        0    \n",
            "Opsterland              0    \n",
            "Schiermonnikoog         0    \n",
            "Smallingerland          0    \n",
            "Terschelling            0    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhtI-tbU0Soe"
      },
      "source": [
        "Note: Your delimiter was not filled in (correctly) if you got one of these errors:\n",
        "\n",
        "```python\n",
        "TypeError: \"delimiter\" must be a 1-character string\n",
        "KeyError: 'Municipality_name'\n",
        "```\n",
        "\n",
        "## Metadata\n",
        "\n",
        "Alright, this is much better that looking at raw text, like we did before parsing. We'll get to even better views of the data later. First, let's take a look at some *metadata* -- data about data.\n",
        "- The number of datapoints\n",
        "- The number of columns\n",
        "- The names of the columns (again)\n",
        "- The number of missing or empty values\n",
        "- The number of unique values in each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2iHjy7d0Sof",
        "outputId": "a3840d85-43fa-49e9-cc1b-b9838a8960d3"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "print(f'Number of datapoints: {len(data_dicts)}')\n",
        "print(f'Number of columns: {len(data_dicts[0])}')\n",
        "print('Column names:')\n",
        "for k in data_dicts[0].keys():\n",
        "    print(f'- {k}')\n",
        "    \n",
        "unique_vals = [set() for _ in data_dicts[0].keys()]\n",
        "missing = 0\n",
        "for datapoint in data_dicts:\n",
        "    for i, val in enumerate(datapoint.values()):\n",
        "        unique_vals[i].add(val)\n",
        "        if val is None or val == '':\n",
        "            missing += 1\n",
        "print(f'Missing/empty values: {missing}')\n",
        "\n",
        "print('Number of unique values:')\n",
        "for i, k in enumerate(data_dicts[0].keys()):\n",
        "    print('- {:<25}{:5}'.format(k, len(unique_vals[i])))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of datapoints: 148176\n",
            "Number of columns: 12\n",
            "Column names:\n",
            "- Date_of_report\n",
            "- Date_of_publication\n",
            "- Municipality_code\n",
            "- Municipality_name\n",
            "- Province\n",
            "- Security_region_code\n",
            "- Security_region_name\n",
            "- Municipal_health_service\n",
            "- ROAZ_region\n",
            "- Total_reported\n",
            "- Hospital_admission\n",
            "- Deceased\n",
            "Missing/empty values: 22736\n",
            "Number of unique values:\n",
            "- Date_of_report               1\n",
            "- Date_of_publication        392\n",
            "- Municipality_code          353\n",
            "- Municipality_name          353\n",
            "- Province                    12\n",
            "- Security_region_code        26\n",
            "- Security_region_name        26\n",
            "- Municipal_health_service    25\n",
            "- ROAZ_region                 12\n",
            "- Total_reported             366\n",
            "- Hospital_admission          30\n",
            "- Deceased                    20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ2O64630Soi"
      },
      "source": [
        "**6. Note three questions that you have about the data based on this metadata. It might be something like:**\n",
        "\n",
        "> **\"What is the first and last *date of publication* in the dataset?\"**\n",
        "\n",
        "*TODO: 1. why are there missing or empty values?\n",
        "2. which municipal_health_service operates in two security regions?\n",
        "3. Is there a one on one relationship on the municipality_code and the Municipality_name? \n",
        "\n",
        "**7. Note another metadata property that you would like to know about that's not listed here.**\n",
        "\n",
        "Are there any duplicates in the metadata? \n",
        "\n",
        "## Working with dates\n",
        "\n",
        "Looking at the metadata is a good way to get a feel for what a dataset looks like, and what type of questions you can answer with it. Let's use our example question to proceed with data preparation:\n",
        "\n",
        "> What is the first and last *date of publication* in the dataset?\n",
        "\n",
        "To answer this question, we can't just assume the first date is at the top and the last date is at the bottom, or vice versa. We need some way to do compare the dates and find out which one is the first and which one is the last. Let's first inspect a few entries in the `Date_of_publication` column to see what they look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICeSUmJD0Soj",
        "outputId": "1002898c-7c0e-4da9-d398-75540b41a1a9"
      },
      "source": [
        "print('The current datatype for the Date_of_publication column is:', type(data_dicts[0]['Date_of_publication']))\n",
        "for row in data_dicts[::int(len(data_dicts) / 20)]:\n",
        "    print(row['Date_of_publication'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The current datatype for the Date_of_publication column is: <class 'str'>\n",
            "27-2-2020\n",
            "17-3-2020\n",
            "6-4-2020\n",
            "25-4-2020\n",
            "15-5-2020\n",
            "3-6-2020\n",
            "23-6-2020\n",
            "13-7-2020\n",
            "1-8-2020\n",
            "21-8-2020\n",
            "9-9-2020\n",
            "29-9-2020\n",
            "19-10-2020\n",
            "7-11-2020\n",
            "27-11-2020\n",
            "16-12-2020\n",
            "5-1-2021\n",
            "25-1-2021\n",
            "13-2-2021\n",
            "5-3-2021\n",
            "24-3-2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITgA2Dq40Soj"
      },
      "source": [
        "We see that the data type is `str`, which is short for *string*, the programming term for *text*. We can't do any clever comparing with just text. We need to *parse* these dates to be able to make comparisons between them. \n",
        "\n",
        "Fortunately, the dates are then specified in a certain *date format*. For example, in the Netherlands people often write '24/12/1980' for the 24th day of December in the year 1980. We could specify that format as `DD/MM/YYYY`.\n",
        "\n",
        "- `DD` stands for 'Two numbers that represent the day'.\n",
        "- `MM` stands for 'Two numbers that represent the month'.\n",
        "- `YYYY` stands for 'Four numbers that represent the year'.\n",
        "\n",
        "If they wrote `-` instead of `/`, like so: '24-12-1980', the format would be `DD-MM-YYYY`.\n",
        "\n",
        "**8. What is the *date format* in the `Date_of_publication` column in our dataset?**\n",
        "\n",
        "*TODO: DD-MM-YYYY\n",
        "\n",
        "**9. Fill in this format in the placeholder in the code block below.**\n",
        "\n",
        "- **Use `%Y` for `YYYY`.**\n",
        "- **Use `%m` for `MM`.**\n",
        "- **Use `%d` for `DD`.**\n",
        "\n",
        "**For example, the Dutch date format ('DD/MM/YYYY' would be `'%d/%m/%Y'`)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "6H127bmi0Sok",
        "outputId": "75109ead-47fb-431e-a789-5f09411a8bcb"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# TODO: Fill in date format for PLACEHOLDER in the next line.\n",
        "date_format ='%d/%m/%Y'\n",
        "# Don't modify anything below this line.\n",
        "\n",
        "for row in data_dicts:\n",
        "    formatted_date = datetime.strptime(row['Date_of_publication'], date_format).date()\n",
        "    row['Date_of_publication'] = formatted_date\n",
        "    \n",
        "print('The new datatype for the Date_of_publication column is:', type(data_dicts[0]['Date_of_publication']))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a5adfbc58b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mformatted_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date_of_publication'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date_of_publication'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatted_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    576\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0;32m--> 359\u001b[0;31m                          (data_string, format))\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n",
            "\u001b[0;31mValueError\u001b[0m: time data '27-2-2020' does not match format '%d/%m/%Y'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O1gdHf20Sol"
      },
      "source": [
        "If you get an error like the following, your `date_format` is not correct yet.\n",
        "\n",
        "```python\n",
        "ValueError: time data '2020-02-27' does not match format 'PLACEHOLDER'\n",
        "```\n",
        "\n",
        "After filling in `date_format` correctly, you should see a line that confirms that the new datatype for this column is `datetime.date`. Great! Now we can compare the dates in the column and answer our original question:\n",
        "\n",
        "> What is the first and last *date of publication* in the dataset?\n",
        "\n",
        "We can now compare the dates with:\n",
        "\n",
        "- `a > b`: this checks if `a` is *later* than `b`.\n",
        "- `a < b`: this checks if `a` is *earlier* than `b`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kGbSJbd0Sol"
      },
      "source": [
        "# We make the assumption that the date of publication of the first datapoint is the only date. \n",
        "first_date_of_publication = data_dicts[0]['Date_of_publication']\n",
        "last_date_of_publication = data_dicts[0]['Date_of_publication']\n",
        "# Then we see if we can find any earlier ones, or later ones.\n",
        "for row in data_dicts:\n",
        "    # Check if this date is earlier than the currently known first date of publication\n",
        "    if row['Date_of_publication'] < first_date_of_publication:\n",
        "        # If so, this is now the new earliest date.\n",
        "        first_date_of_publication = row['Date_of_publication']\n",
        "    # Check if this date is later than the currently known last date of publication\n",
        "    elif row['Date_of_publication'] > last_date_of_publication:\n",
        "        # If so, this is now the new latest date.\n",
        "        last_date_of_publication = row['Date_of_publication']\n",
        "\n",
        "print(f'The first date of publication is {first_date_of_publication}')\n",
        "print(f'The last date of publication is {last_date_of_publication}')\n",
        "print(f'The dataset spans {(last_date_of_publication - first_date_of_publication).days} days')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X78YiDH0Som"
      },
      "source": [
        "Cool! We now have a better understanding of what the `Date_of_publication` column looks like.\n",
        "\n",
        "**10. Explain, in your own words, what a string is.**\n",
        "\n",
        "*TODO: This is a text, like the word: hello \n",
        "\n",
        "**11. Explain, in your own words, what a date string is.**\n",
        "\n",
        "*TODO: a string that specifier the date/time\n",
        "\n",
        "**12. Explain, in your own words, why we converted date strings to a `datetime.date` type.**\n",
        "\n",
        "*TODO: To have the correct time in our data\n",
        "\n",
        "\n",
        "## Working with numbers\n",
        "\n",
        "We'd like to wrap up this lesson with a nice visualization of how many COVID cases were reported over time in a certain municipality. For that we not only have to work with strings and dates, but also with *numbers*. We can find the right number in the `Total_reported` column, but again, it's not yet in the right format. It's a string, while it needs to be a number.\n",
        "\n",
        "Let's apply the same strategy that we used with dates before. Note that if you run the cell below multiple times, it will no longer show that the column values used to be a strings -- they were converted the first time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYa2Ky5X0Soo"
      },
      "source": [
        "print('The current datatype for the Total_reported column is:', type(data_dicts[0]['Total_reported']))\n",
        "for row in data_dicts:\n",
        "    row['Total_reported'] = int(row['Total_reported'])\n",
        "print('The new datatype for the Total_reported column is:', type(data_dicts[0]['Total_reported']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svbpkByU0Sop"
      },
      "source": [
        "The new datatype for the `Total_reported` column is `int`, which stands for *integer*. This is the programming term for *whole number*. Bonus: the term for a decimal number is *float*.\n",
        "\n",
        "**13. Which variable in the code snippet below is an integer? (write an `x` in the right box)**\n",
        "\n",
        "```python\n",
        "a = 'Hello, world!'\n",
        "b = 42\n",
        "```\n",
        "\n",
        "- [ ] `a`\n",
        "- [ x] `b`\n",
        "\n",
        "**14. Which variable in the code snippet below is an integer? (write an `x` in the right box)**\n",
        "\n",
        "```python\n",
        "a = '42'\n",
        "b = 42\n",
        "```\n",
        "\n",
        "- [ ] `a`\n",
        "- [ x] `b`\n",
        "\n",
        "Now that the `Total_reported` column has the correct datatype, let's write a script that tells us the reported number per municipality. For convenience, we first print a list of all the municipalities in the dataset.\n",
        "\n",
        "**15. Choose one of the municipalities printed in the code block below. Then fill it in (exactly as it was displayed) in the next cell and run it to find the total number of reported cases in that municipality.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeVB8q8D0Sor"
      },
      "source": [
        "for m in sorted(unique_vals[3]):\n",
        "    if m != '':\n",
        "        print('-', m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjeyGVQc0Sos"
      },
      "source": [
        "# TODO: FILL IN THE MUNICIPALITY YOU'RE INTERESTED IN HERE\n",
        "municipality = 'GM0034'\n",
        "# DON'T MODIFY ANYTHING BELOW THIS LINE\n",
        "\n",
        "reported = 0\n",
        "for row in data_dicts:\n",
        "    if row['Municipality_name'] == municipality:\n",
        "        reported += row['Total_reported']\n",
        "print(f'The total number of reported cases in {municipality} is {reported}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLXxoyLl0Sos"
      },
      "source": [
        "Because we have all the data types in order, we can also easily plot the development of new reported cases for that same municipality. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Lr2h1d0Sot"
      },
      "source": [
        "new_cases_per_day = defaultdict(int)\n",
        "for row in data_dicts:\n",
        "        if row['Municipality_name'] == municipality:\n",
        "            new_cases_per_day[row['Date_of_publication']] += row['Total_reported']\n",
        "new_cases_per_day = sorted(new_cases_per_day.items(), key=lambda x: x[0])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,9))\n",
        "ax.plot([date for date, _ in new_cases_per_day], [cases for _, cases in new_cases_per_day])\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Number of new cases');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYi7ncMh0Sot"
      },
      "source": [
        "## Missing Data\n",
        "\n",
        "Finally, a visualization! Let's tackle one final problem: missing data. When we were looking at the metadata, we found that we have $22736$ missing or empty values. Let's print a few datapoints that contain missing values to see what we're dealing with exactly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAonfzQq0Sot"
      },
      "source": [
        "for i, row in enumerate(data_dicts):\n",
        "    missing_keys = []\n",
        "    for key, val in row.items():\n",
        "        if val == '':\n",
        "            missing_keys.append(key)\n",
        "    if missing_keys:\n",
        "        print(f'Row {i} contains empty values for: {missing_keys}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5PMzPQ30Sou"
      },
      "source": [
        "**16. What column(s) is/are missing most often?**\n",
        "\n",
        "*TODO: the values for municipality code and municipality name\n",
        "\n",
        "Missing data may become a problem if we want to draw comparisons between certain parts of the data. Still, there is no universal and definitive *correct approach* to solving the problem of missing data. In fact, in this case there might actually not be a good way to fill in the missing municipalities here.\n",
        "\n",
        "For the sake of exercise, we will create a new dataset for your chosen municipality where the `Total_reported` new cases will be replaced with the impossible number `-1` from a number of the dates.\n",
        "\n",
        "**17. Why is `-1` an impossible number here?**\n",
        "\n",
        "*TODO: that is invalid data. The dataset will not allow this (minteken).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BOtheNb0Sov"
      },
      "source": [
        "noisy_new_cases_per_day = [(date, cases) if np.random.rand() < 0.8\n",
        "                           else (date, -1)\n",
        "                           for date, cases in new_cases_per_day]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,9))\n",
        "ax.plot([date for date, _ in new_cases_per_day],\n",
        "        [cases for _, cases in new_cases_per_day], '.', label='true data')\n",
        "ax.plot([date for date, _ in noisy_new_cases_per_day],\n",
        "        [cases for _, cases in noisy_new_cases_per_day],\n",
        "        label='noisy data')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Number of new cases')\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWPUGusS0Sow"
      },
      "source": [
        "This plot is a lot more messy than the clean data plot, in addition to also showing the impossible number `-1`.\n",
        "\n",
        "**18. What would be a good way to fill in the missing values? You will not need to implement them, so use your imagination.**\n",
        "\n",
        "*TODO: maybe a zero will help?, not sure \n",
        "\n",
        "Here we'll use the mean of the two surrounding dates' values. For example:\n",
        "\n",
        "1. `2020-02-03` is missing\n",
        "2. We take the values from the day before, `2020-02-02`, and the day after, `2020-02-04`. If the data from the day before or after is not available, we use the nearest available datapoint instead.\n",
        "3. We add them up\n",
        "4. Divide them by $2$\n",
        "5. We insert the result as the value for `2020-02-03`.\n",
        "\n",
        "This is a simple way of doing **interpolation** -- estimating missing values within the range of the data we have. This is the opposite of **extrapolation**, where we have estimate values *outside* of the range of the data we have.\n",
        "\n",
        "Let's see what the implementation and the result look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpZzdnTq0Sox"
      },
      "source": [
        "interpolated_data = []\n",
        "max_data_index = len(noisy_new_cases_per_day) - 1\n",
        "for i, (date, x) in enumerate(noisy_new_cases_per_day):\n",
        "    # If we have an impossible value\n",
        "    if x == -1:\n",
        "        delta_left = 1\n",
        "        # Scan the left side for values that are not -1\n",
        "        while noisy_new_cases_per_day[i - delta_left][1] == -1:\n",
        "            delta_left += 1\n",
        "            # If we're outside of the data we can't do interpolation. It would be extrapolation.\n",
        "            if i - delta_left < 0:\n",
        "                continue\n",
        "    \n",
        "        # Scan the right side for values that are not -1\n",
        "        delta_right = 1\n",
        "        while noisy_new_cases_per_day[i + delta_right][1] == -1:\n",
        "            delta_right += 1\n",
        "            # If we're outside of the data we can't do interpolation. It would be extrapolation.\n",
        "            if i + delta_right > max_data_index:\n",
        "                continue\n",
        "        \n",
        "        # Finally use the mean of two nearest useful values\n",
        "        interpolated_value = ((noisy_new_cases_per_day[i - delta_left][1]\n",
        "                               + noisy_new_cases_per_day[i + delta_right][1])\n",
        "                              / 2)\n",
        "        interpolated_data.append((date, interpolated_value))\n",
        "    else:\n",
        "        interpolated_data.append((date, x))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,9))\n",
        "ax.plot([date for date, _ in new_cases_per_day],\n",
        "        [cases for _, cases in new_cases_per_day], '.', label='true data')\n",
        "ax.plot([date for date, _ in interpolated_data],\n",
        "        [cases for _, cases in interpolated_data],\n",
        "        label='interpolated data')\n",
        "ax.plot([date for (date, cases) in noisy_new_cases_per_day if cases == -1],\n",
        "        [cases for _, cases in noisy_new_cases_per_day if cases == -1], '.',\n",
        "        label='previously missing data')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Number of new cases')\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFqyPbRO0So0"
      },
      "source": [
        "**19. Is this a good way to fill in missing values, in your opinion? Explain.**\n",
        "\n",
        "*TODO: the data above doesnt give the right answer. \n",
        "**20. In which cases will this way of filling in missing values work well, and when will it not work well at all? Give an example for both cases.**\n",
        "\n",
        "*TODO: It works well if you have strings maybe? and not numeric? That is a guess, i am not sure and i can not even find this answer online. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfrtq7vA0So0"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Data preparation may not be the most glamorous part of data analytics, but it is quite important. If we do not do it well, every analytics step that comes after will suffer. It is as they say: *garbage in, garbage out*.\n",
        "\n",
        "It is also good to know that since most data preparation steps are quite general, there are plenty of tools that make doing it a lot easier and faster. All of the above filtering, selecting and interpolating can be done in a few lines of code! But now *you* know how it works under the hood, and why it's so important!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCZqRcPk0So1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}